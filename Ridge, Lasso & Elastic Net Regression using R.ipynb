{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12408afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Package to fit ridge/lasso/elastic net models\n",
    "\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ecd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574cb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1\n",
    "## 4085 useless variables in the model, only 15 that are useful.\n",
    "## Also, not much data relative to the number of parameters.\n",
    "## 1,000 samples and 5,000 parameters.\n",
    "\n",
    "\n",
    "n <- 1000    # Number of observations\n",
    "p <- 5000    # Number of predictors included in model\n",
    "\n",
    "real_p <- 15   # Number of true predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c317441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the data\n",
    "\n",
    "x <- matrix(rnorm(n*p), nrow=n, ncol=p)\n",
    "\n",
    "y <- apply(x[,1:real_p], 1, sum) + rnorm(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e433a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into training and testing datasets.\n",
    "## 2/3rds of the data will be used for Training and 1/3 of the\n",
    "## data will be used for Testing.\n",
    "\n",
    "train_rows <- sample(1:n, .66*n)\n",
    "\n",
    "x.train <- x[train_rows, ]\n",
    "x.test <- x[-train_rows, ]\n",
    "\n",
    "y.train <- y[train_rows]\n",
    "y.test <- y[-train_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53cde1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we will use 10-fold Cross Validation to determine the optimal value for lambda for...\n",
    "\n",
    "## alpha = 0, Ridge Regression\n",
    "\n",
    "alpha0.fit <- cv.glmnet(x.train, y.train, type.measure=\"mse\", alpha=0, family=\"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b67db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's run the Testing dataset on the model created for\n",
    "\n",
    "## alpha = 0 (i.e. Ridge Regression).\n",
    "\n",
    "alpha0.predicted <- predict(alpha0.fit, s=alpha0.fit$lambda.1se, newx=x.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb68717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## s = is the \"size\" of the penalty that we want to use, and\n",
    "##     thus, corresponds to lambda. (I believe that glmnet creators\n",
    "##     decided to use 's' instead of lambda just in case they \n",
    "##     eventually coded up a version that let you specify the \n",
    "##     individual lambdas, but I'm not sure.)\n",
    "##\n",
    "##     In this case, we set 's' to \"lambda.1se\", which is\n",
    "##     the value for lambda that results in the simplest model\n",
    "##     such that the cross validation error is within one \n",
    "##     standard error of the minimum.\n",
    "##     \n",
    "##     If we wanted to to specify the lambda that results in the\n",
    "##     model with the minimum cross valdiation error, not a model\n",
    "##     within one SE of of the minimum, we would \n",
    "##     set 's' to \"lambda.min\".\n",
    "##\n",
    "##     Choice of lambda.1se vs lambda.min boils down to this...\n",
    "##     Statistically speaking, the cross validation error for \n",
    "##     lambda.1se is indistinguisable from the cross validation error\n",
    "##     for lambda.min, since they are within 1 SE of each other. \n",
    "##     So we can pick the simpler model without\n",
    "##     much risk of severely hindering the ability to accurately\n",
    "##     predict values for 'y' given values for 'x'.\n",
    "##\n",
    "##     All that said, lambda.1se only makes the model simpler when\n",
    "##     alpha != 0, since we need some Lasso regression mixed in\n",
    "##     to remove variables from the model. However, to keep things\n",
    "##     consistant when we compare different alphas, it makes sense\n",
    "##     to use lambda.1se all the time.\n",
    "##\n",
    "## newx = is the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa689f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "14.8845879687685"
      ],
      "text/latex": [
       "14.8845879687685"
      ],
      "text/markdown": [
       "14.8845879687685"
      ],
      "text/plain": [
       "[1] 14.88459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lastly, let's calculate the Mean Squared Error (MSE) for the model\n",
    "## created for alpha = 0.\n",
    "## The MSE is the mean of the sum of the squared difference between \n",
    "## the predicted 'y' values and the true 'y' values in the \n",
    "## Testing dataset...\n",
    "\n",
    "mean((y.test - alpha0.predicted)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6e1fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.18470051271456"
      ],
      "text/latex": [
       "1.18470051271456"
      ],
      "text/markdown": [
       "1.18470051271456"
      ],
      "text/plain": [
       "[1] 1.184701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## alpha = 1, Lasso Regression\n",
    "\n",
    "alpha1.fit <- cv.glmnet(x.train, y.train, type.measure=\"mse\", alpha=1, family=\"gaussian\")\n",
    "\n",
    "alpha1.predicted <- predict(alpha1.fit, s=alpha1.fit$lambda.1se, newx=x.test)\n",
    "\n",
    "mean((y.test - alpha1.predicted)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "364ab30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.2379695989567"
      ],
      "text/latex": [
       "1.2379695989567"
      ],
      "text/markdown": [
       "1.2379695989567"
      ],
      "text/plain": [
       "[1] 1.23797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## alpha = 0.5, a 50/50 mixture of Ridge and Lasso Regression\n",
    "\n",
    "alpha0.5.fit <- cv.glmnet(x.train, y.train, type.measure=\"mse\", alpha=0.5, family=\"gaussian\")\n",
    "\n",
    "alpha0.5.predicted <- predict(alpha0.5.fit, s=alpha0.5.fit$lambda.1se, newx=x.test)\n",
    "\n",
    "mean((y.test - alpha0.5.predicted)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3142a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## However, the best thing to do is just try a bunch of different values for alpha rather than guess which one will be best.\n",
    "\n",
    "## The following loop uses 10-fold Cross Validation to determine the optimal value for lambda for \n",
    "## alpha = 0, 0.1, ... , 0.9, 1.0 using the Training dataset.\n",
    "\n",
    "\n",
    "list.of.fits <- list()\n",
    "\n",
    "for (i in 0:10) {\n",
    "  ## Here's what's going on in this loop...\n",
    "  ## We are testing alpha = i/10. This means we are testing\n",
    "  ## alpha = 0/10 = 0 on the first iteration, alpha = 1/10 = 0.1 on\n",
    "  ## the second iteration etc.\n",
    "  \n",
    "  ## First, make a variable name that we can use later to refer\n",
    "  ## to the model optimized for a specific alpha.\n",
    "  ## For example, when alpha = 0, we will be able to refer to \n",
    "  ## that model with the variable name \"alpha0\".\n",
    "  fit.name <- paste0(\"alpha\", i/10)\n",
    "  \n",
    "  ## Now fit a model (i.e. optimize lambda) and store it in a list that \n",
    "  ## uses the variable name we just created as the reference.\n",
    "  list.of.fits[[fit.name]] <- cv.glmnet(x.train, y.train, type.measure=\"mse\", alpha=i/10, family=\"gaussian\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba51f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we see which alpha (0, 0.1, ... , 0.9, 1) does the best job predicting the values in the Testing dataset.\n",
    "\n",
    "\n",
    "results <- data.frame()\n",
    "\n",
    "for (i in 0:10) {\n",
    "  fit.name <- paste0(\"alpha\", i/10)\n",
    "  \n",
    "  ## Use each model to predict 'y' given the Testing dataset\n",
    "  predicted <- predict(list.of.fits[[fit.name]], s=list.of.fits[[fit.name]]$lambda.1se, newx=x.test)\n",
    "  \n",
    "  ## Calculate the Mean Squared Error...\n",
    "  mse <- mean((y.test - predicted)^2)\n",
    "  \n",
    "  ## Store the results\n",
    "  temp <- data.frame(alpha=i/10, mse=mse, fit.name=fit.name)\n",
    "  results <- rbind(results, temp)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99537a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 11 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>alpha</th><th scope=col>mse</th><th scope=col>fit.name</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0</td><td>14.918840</td><td>alpha0  </td></tr>\n",
       "\t<tr><td>0.1</td><td> 2.256924</td><td>alpha0.1</td></tr>\n",
       "\t<tr><td>0.2</td><td> 1.472927</td><td>alpha0.2</td></tr>\n",
       "\t<tr><td>0.3</td><td> 1.362394</td><td>alpha0.3</td></tr>\n",
       "\t<tr><td>0.4</td><td> 1.259794</td><td>alpha0.4</td></tr>\n",
       "\t<tr><td>0.5</td><td> 1.252103</td><td>alpha0.5</td></tr>\n",
       "\t<tr><td>0.6</td><td> 1.253330</td><td>alpha0.6</td></tr>\n",
       "\t<tr><td>0.7</td><td> 1.212927</td><td>alpha0.7</td></tr>\n",
       "\t<tr><td>0.8</td><td> 1.184028</td><td>alpha0.8</td></tr>\n",
       "\t<tr><td>0.9</td><td> 1.182919</td><td>alpha0.9</td></tr>\n",
       "\t<tr><td>1.0</td><td> 1.184701</td><td>alpha1  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 11 × 3\n",
       "\\begin{tabular}{lll}\n",
       " alpha & mse & fit.name\\\\\n",
       " <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.0 & 14.918840 & alpha0  \\\\\n",
       "\t 0.1 &  2.256924 & alpha0.1\\\\\n",
       "\t 0.2 &  1.472927 & alpha0.2\\\\\n",
       "\t 0.3 &  1.362394 & alpha0.3\\\\\n",
       "\t 0.4 &  1.259794 & alpha0.4\\\\\n",
       "\t 0.5 &  1.252103 & alpha0.5\\\\\n",
       "\t 0.6 &  1.253330 & alpha0.6\\\\\n",
       "\t 0.7 &  1.212927 & alpha0.7\\\\\n",
       "\t 0.8 &  1.184028 & alpha0.8\\\\\n",
       "\t 0.9 &  1.182919 & alpha0.9\\\\\n",
       "\t 1.0 &  1.184701 & alpha1  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 11 × 3\n",
       "\n",
       "| alpha &lt;dbl&gt; | mse &lt;dbl&gt; | fit.name &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 0.0 | 14.918840 | alpha0   |\n",
       "| 0.1 |  2.256924 | alpha0.1 |\n",
       "| 0.2 |  1.472927 | alpha0.2 |\n",
       "| 0.3 |  1.362394 | alpha0.3 |\n",
       "| 0.4 |  1.259794 | alpha0.4 |\n",
       "| 0.5 |  1.252103 | alpha0.5 |\n",
       "| 0.6 |  1.253330 | alpha0.6 |\n",
       "| 0.7 |  1.212927 | alpha0.7 |\n",
       "| 0.8 |  1.184028 | alpha0.8 |\n",
       "| 0.9 |  1.182919 | alpha0.9 |\n",
       "| 1.0 |  1.184701 | alpha1   |\n",
       "\n"
      ],
      "text/plain": [
       "   alpha mse       fit.name\n",
       "1  0.0   14.918840 alpha0  \n",
       "2  0.1    2.256924 alpha0.1\n",
       "3  0.2    1.472927 alpha0.2\n",
       "4  0.3    1.362394 alpha0.3\n",
       "5  0.4    1.259794 alpha0.4\n",
       "6  0.5    1.252103 alpha0.5\n",
       "7  0.6    1.253330 alpha0.6\n",
       "8  0.7    1.212927 alpha0.7\n",
       "9  0.8    1.184028 alpha0.8\n",
       "10 0.9    1.182919 alpha0.9\n",
       "11 1.0    1.184701 alpha1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## View the results\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2036cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 2\n",
    "## 3500 useless variables, 1500 useful (so lots of useful variables)\n",
    "## 1,000 samples and 5,000 parameters\n",
    "\n",
    "\n",
    "set.seed(42) # Set seed for reproducibility\n",
    "\n",
    "n <- 1000    # Number of observations\n",
    "p <- 5000     # Number of predictors included in model\n",
    "real_p <- 1500  # Number of true predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f47bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the data\n",
    "\n",
    "x <- matrix(rnorm(n*p), nrow=n, ncol=p)\n",
    "y <- apply(x[,1:real_p], 1, sum) + rnorm(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95152b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (2/3) and test (1/3) sets\n",
    "\n",
    "train_rows <- sample(1:n, .66*n)\n",
    "\n",
    "x.train <- x[train_rows, ]\n",
    "x.test <- x[-train_rows, ]\n",
    "\n",
    "y.train <- y[train_rows]\n",
    "y.test <- y[-train_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddfa5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list.of.fits <- list()\n",
    "\n",
    "for (i in 0:10) {\n",
    "  fit.name <- paste0(\"alpha\", i/10)\n",
    "  \n",
    "  list.of.fits[[fit.name]] <- cv.glmnet(x.train, y.train, type.measure=\"mse\", alpha=i/10, family=\"gaussian\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba050465",
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- data.frame()\n",
    "\n",
    "for (i in 0:10) {\n",
    "  fit.name <- paste0(\"alpha\", i/10)\n",
    "  \n",
    "  predicted <- predict(list.of.fits[[fit.name]], s=list.of.fits[[fit.name]]$lambda.1se, newx=x.test)\n",
    "  \n",
    "  mse <- mean((y.test - predicted)^2)\n",
    "  \n",
    "  temp <- data.frame(alpha=i/10, mse=mse, fit.name=fit.name)\n",
    "  results <- rbind(results, temp)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8970227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 11 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>alpha</th><th scope=col>mse</th><th scope=col>fit.name</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0</td><td>1400.375</td><td>alpha0  </td></tr>\n",
       "\t<tr><td>0.1</td><td>1545.035</td><td>alpha0.1</td></tr>\n",
       "\t<tr><td>0.2</td><td>1545.035</td><td>alpha0.2</td></tr>\n",
       "\t<tr><td>0.3</td><td>1545.035</td><td>alpha0.3</td></tr>\n",
       "\t<tr><td>0.4</td><td>1545.035</td><td>alpha0.4</td></tr>\n",
       "\t<tr><td>0.5</td><td>1545.035</td><td>alpha0.5</td></tr>\n",
       "\t<tr><td>0.6</td><td>1545.035</td><td>alpha0.6</td></tr>\n",
       "\t<tr><td>0.7</td><td>1545.035</td><td>alpha0.7</td></tr>\n",
       "\t<tr><td>0.8</td><td>1545.035</td><td>alpha0.8</td></tr>\n",
       "\t<tr><td>0.9</td><td>1545.035</td><td>alpha0.9</td></tr>\n",
       "\t<tr><td>1.0</td><td>1545.035</td><td>alpha1  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 11 × 3\n",
       "\\begin{tabular}{lll}\n",
       " alpha & mse & fit.name\\\\\n",
       " <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.0 & 1400.375 & alpha0  \\\\\n",
       "\t 0.1 & 1545.035 & alpha0.1\\\\\n",
       "\t 0.2 & 1545.035 & alpha0.2\\\\\n",
       "\t 0.3 & 1545.035 & alpha0.3\\\\\n",
       "\t 0.4 & 1545.035 & alpha0.4\\\\\n",
       "\t 0.5 & 1545.035 & alpha0.5\\\\\n",
       "\t 0.6 & 1545.035 & alpha0.6\\\\\n",
       "\t 0.7 & 1545.035 & alpha0.7\\\\\n",
       "\t 0.8 & 1545.035 & alpha0.8\\\\\n",
       "\t 0.9 & 1545.035 & alpha0.9\\\\\n",
       "\t 1.0 & 1545.035 & alpha1  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 11 × 3\n",
       "\n",
       "| alpha &lt;dbl&gt; | mse &lt;dbl&gt; | fit.name &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 0.0 | 1400.375 | alpha0   |\n",
       "| 0.1 | 1545.035 | alpha0.1 |\n",
       "| 0.2 | 1545.035 | alpha0.2 |\n",
       "| 0.3 | 1545.035 | alpha0.3 |\n",
       "| 0.4 | 1545.035 | alpha0.4 |\n",
       "| 0.5 | 1545.035 | alpha0.5 |\n",
       "| 0.6 | 1545.035 | alpha0.6 |\n",
       "| 0.7 | 1545.035 | alpha0.7 |\n",
       "| 0.8 | 1545.035 | alpha0.8 |\n",
       "| 0.9 | 1545.035 | alpha0.9 |\n",
       "| 1.0 | 1545.035 | alpha1   |\n",
       "\n"
      ],
      "text/plain": [
       "   alpha mse      fit.name\n",
       "1  0.0   1400.375 alpha0  \n",
       "2  0.1   1545.035 alpha0.1\n",
       "3  0.2   1545.035 alpha0.2\n",
       "4  0.3   1545.035 alpha0.3\n",
       "5  0.4   1545.035 alpha0.4\n",
       "6  0.5   1545.035 alpha0.5\n",
       "7  0.6   1545.035 alpha0.6\n",
       "8  0.7   1545.035 alpha0.7\n",
       "9  0.8   1545.035 alpha0.8\n",
       "10 0.9   1545.035 alpha0.9\n",
       "11 1.0   1545.035 alpha1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
